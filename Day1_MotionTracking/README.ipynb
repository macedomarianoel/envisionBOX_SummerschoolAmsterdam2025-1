{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5bea6b",
   "metadata": {},
   "source": [
    "# Pose2Sim workshop\n",
    "EnvisionBOX Summer School, 2025, Amsterdam. Presented by David Pagnon\n",
    "\n",
    "<bt><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d6ca9",
   "metadata": {},
   "source": [
    "`Pose2Sim` provides a workflow for 3D markerless kinematics (human or animal), as an alternative to traditional marker-based MoCap methods. \n",
    "\n",
    "**Pose2Sim** is free and open-source, requiring low-cost hardware but with research-grade accuracy and production-grade robustness. It gives maximum control over clearly explained parameters. Any combination of phones, webcams, or GoPros can be used with fully clothed subjects, so it is particularly adapted to the sports field, the doctor's office, or for outdoor 3D animation capture.\n",
    "\n",
    "***Note:*** For real-time analysis with a single camera, please consider **[Sports2D](https://github.com/davidpagnon/Sports2D)** (note that the motion must lie in the sagittal or frontal plane). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video, display\n",
    "\n",
    "display(Video('Pose2Sim_small.mp4', embed=True, width=1280, height=720))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd61b4e",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "1. [Install and import libraries](#install-and-import-libraries)\n",
    "   1. [Install MiniConda](#install-miniconda)\n",
    "   2. [Clone the repository](#clone-the-repository)\n",
    "   3. [Install Pose2Sim](#install-pose2sim)\n",
    "\n",
    "2. [Try Pose2Sim Demo](#try-pose2sim-demo)\n",
    "    1. [Copy the Pose2Sim demo files to the current folder](#copy-the-pose2sim-demo-files-to-the-current-folder)\n",
    "    2. [Run Pose2Sim demo](#run-pose2sim-demo)\n",
    "    3. [Understand what is happening](#understand-what-is-happening)\n",
    "    4. [Visualize the results](#visualize-the-results)\n",
    "\n",
    "3. [Run on the Tragic Talkers dataset](#run-on-the-tragic-talkers-dataset)\n",
    "   1. [Choose a subset](#choose-a-subset)\n",
    "   2. [Convert the calibration files to the Pose2Sim format](#convert-the-calibration-files-to-the-pose2sim-format)\n",
    "   3. [Run Pose2Sim with model with hands](#run-pose2sim-with-model-with-hands)\n",
    "   4. [Optional: Try it on a scene with multiple persons](#optional-try-it-on-a-scene-with-multiple-persons)\n",
    "\n",
    "4. [Run on custom data](#run-on-custom-data)\n",
    "   1. [Get your command line ready](#get-your-command-line-ready)\n",
    "   2. [Record and share videos from phones](#record-and-share-videos-from-phones)\n",
    "   3. [Organize the videos](#organize-the-videos)\n",
    "   4. [Edit the Configuration files](#edit-the-configuration-files)\n",
    "   5. [Run Pose2Sim](#run-pose2sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a62071",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728f618",
   "metadata": {},
   "source": [
    "## Install and import libraries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e116b338",
   "metadata": {},
   "source": [
    "### Install MiniConda\n",
    "\n",
    "Conda will be required to install the dependencies of Pose2Sim.\n",
    "\n",
    "Type `miniconda`in Google, click on the first, link, then \"Download\" on the upper right corner.\\\n",
    "Click `skip registration` and download the `Miniconda installer` (NOT Distribution installer!) for your operating system.\n",
    "\n",
    "Follow the instructions to install it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87428d1",
   "metadata": {},
   "source": [
    "### Clone the repository\n",
    "\n",
    "If not already done, you will need to clone the repository of the Summer School. If you did it already, please pull the last changes anyway (last step).\n",
    "\n",
    "Type `install git` on Google and go to the first link.\\\n",
    "Download and install git.\n",
    "\n",
    "Open `anaconda prompt`.\\\n",
    "Type `cd Desktop` (or any other location where you would like the Summer school files to be stored).\\\n",
    "Clone the repository: `git clone https://github.com/sarkadava/envisionBOX_SummerschoolAmsterdam2025.git`\n",
    "\n",
    "Make sure you have the latest version: `git pull`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fdac80",
   "metadata": {},
   "source": [
    "### Install Pose2Sim\n",
    "\n",
    "***N.B.*** *The following instructions are the same as those in the [Pose2Sim documentation](https://github.com/perfanalytics/pose2sim)*\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45040a10",
   "metadata": {},
   "source": [
    "1. Open `anaconda prompt` \n",
    "2. Create a new conda environement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda create -n Pose2Sim python=3.10 -y \n",
    "conda activate Pose2Sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937335e",
   "metadata": {},
   "source": [
    "3. Install OpenSim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install -c opensim-org opensim -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce806b",
   "metadata": {},
   "source": [
    "4. Also install the [OpenSim GUI](https://simtk.org/projects/opensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e594c",
   "metadata": {},
   "source": [
    "5. Install Pose2Sim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aca6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pose2sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a538154",
   "metadata": {},
   "source": [
    "6. *Optional:* Install the libraries for GPU support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "pip uninstall onnxruntime\n",
    "pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c7f42",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd7311",
   "metadata": {},
   "source": [
    "## Try Pose2Sim Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e54082",
   "metadata": {},
   "source": [
    "### Copy the Pose2Sim demo files to the current folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate Pose2Sim\n",
    "from Pose2Sim import Pose2Sim\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "singleperson_demo_path = Path(Pose2Sim.__file__).parent.resolve() / 'Demo_SinglePerson'\n",
    "\n",
    "\n",
    "!cp -r {singleperson_demo_path} {Path.cwd()}/\n",
    "os.chdir(Path.cwd() / 'Demo_SinglePerson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1e848",
   "metadata": {},
   "source": [
    "   See how the folder is organized:\n",
    "   ```\n",
    "   Trial\n",
    "   ├── calibration \\\n",
    "   ├── videos \\\n",
    "   └── Config.toml\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfac06a",
   "metadata": {},
   "source": [
    "### Run Pose2Sim demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b62697",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pose2Sim.calibration()\n",
    "Pose2Sim.poseEstimation()\n",
    "# Pose2Sim.synchronization() # skipped for now, as it does not work in a Notebook\n",
    "Pose2Sim.personAssociation()\n",
    "Pose2Sim.triangulation()\n",
    "Pose2Sim.filtering()\n",
    "Pose2Sim.markerAugmentation()\n",
    "Pose2Sim.kinematics()\n",
    "\n",
    "# Or equivalently:\n",
    "#Pose2Sim.runAll() \n",
    "# Or:\n",
    "#Pose2Sim.runAll(do_calibration=True, do_poseEstimation=True, do_synchronization=True, do_personAssociation=True, do_triangulation=True, do_filtering=True, do_markerAugmentation=True, do_kinematics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a274a91",
   "metadata": {},
   "source": [
    "### Understand what is happening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97418ce2",
   "metadata": {},
   "source": [
    "This runs all stages of the pipeline on the Demo data with the default parameters. :\n",
    "- **Calibration:** Determining the **intrinsic parameters** of the cameras (focal length, optical center, distortion, ...) and their **extrinsic parameters** (location and orientation).\\ \n",
    "  Here, we just convert a calibration file. Proper calibration will be done this afternoon when we collect our own data\n",
    "- **Pose estimation:** Detecting the points of interest in each video (joint centers, face, etc)\n",
    "- **Synchronization:** Make sure that the same time frame corresponds to the same body position.\\\n",
    "  I did not manage to make the tool work in Jupyter, so we are just going to skip it for now. We will do it again from the command line when we collect our own data.\n",
    "- **Person association:** Make sure that person 1 is associated with person 1 across all cameras\n",
    "- **Triangulation:** Transform all the 2D positions on videos to a 3D position in meters\n",
    "- **Filtering:** Results can be somewhat noisy, especially if we do not have many cameras, if they are not optimally placed, or if calibration is not perfect.\n",
    "- **Marker augmentation:** Add markers to the skeleton to facilitate the inverse kinematics stage.\n",
    "- **Kinematics:** Obtain a biomechanically consistent animated skeleton with adjusted and fixed limb lengths, and joint angle constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5deb98",
   "metadata": {},
   "source": [
    "Have a look at the logs to understand what is going on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56bf2f",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "\n",
    "Open the OpenSim GUI to visualize the results:\n",
    "\n",
    "- File -> Open Model: Open the scaled `.osim` model from Demo_SinglePerson/kinematics\n",
    "- File -> Load Motion: Load the `.mot` motion from Demo_SinglePerson/kinematics\n",
    "- File -> Preview experimental data: Check the markers from Demo_SinglePerson/pose-3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c8613",
   "metadata": {},
   "source": [
    "Optional:\n",
    "- You can also open the .trc and .mot file in Excel or any other spreadsheet software.\n",
    "- You can also look at the positions of cameras and the overlay of the skeleton and markers on videos by using the [Pose2Sim Blender add-on](https://github.com/davidpagnon/Pose2Sim_Blender). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c457fc96",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ab2e5",
   "metadata": {},
   "source": [
    "## Run on the Tragic Talkers dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd295cb",
   "metadata": {},
   "source": [
    "Go back to the original Day1_MotionTracking directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e217b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Path.cwd().parent) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39310b0",
   "metadata": {},
   "source": [
    "### Choose a subset of the dataset to run on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_name = 'femalemonologue2_t3' # Among 'conversation1_t3', 'femalemonologue1_t2', 'femalemonologue2_t3', 'interactive1_t2', 'interactive4_t3', 'male_monologue2_t3'*\n",
    "cameras_to_use = ['01', '11', '12', '22'] # Among ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addddc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pose2Sim import Pose2Sim\n",
    "import shutil\n",
    "\n",
    "sample_folder = Path.cwd().parent / 'Sample'\n",
    "scene_folder = sample_folder/scene_name\n",
    "calibration_folder = sample_folder/'camera_calibration_data'\n",
    "\n",
    "Pose2Sim_scene_folder = Path.cwd() / ('Demo_'+scene_name)\n",
    "Pose2Sim_scene_folder.mkdir(parents=True, exist_ok=True)\n",
    "(Pose2Sim_scene_folder / 'calibration').mkdir(parents=True, exist_ok=True)\n",
    "(Pose2Sim_scene_folder / 'videos').mkdir(parents=True, exist_ok=True)\n",
    "demo_config_path = Path(Pose2Sim.__file__).parent.resolve() / 'Demo_SinglePerson' / 'Config.toml'\n",
    "shutil.copyfile(demo_config_path, Pose2Sim_scene_folder / 'Config.toml')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa884dd",
   "metadata": {},
   "source": [
    "### Convert the calibration files to the Pose2Sim format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290bb49c",
   "metadata": {},
   "source": [
    "Create the Pose2Sim folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402825aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pose2Sim.calibration import toml_write\n",
    "from Pose2Sim.common import rotate_cam, world_to_camera_persp\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "json_calib_files = sorted([list(calibration_folder.glob(f'*{nb}.json'))[0] for nb in cameras_to_use])\n",
    "ret, C, S, D, K, R, T = [], [], [], [], [], [], []\n",
    "for file_path in json_calib_files:\n",
    "    with open(file_path, 'r') as f:\n",
    "        calib_data_cam = json.load(f)['camera']\n",
    "        C.append(file_path.stem)  # Name\n",
    "        S.append([int(calib_data_cam['width']), int(calib_data_cam['height'])]) # Size\n",
    "        D.append([float(d) for d in calib_data_cam['distortion']][:4]) # Distortion\n",
    "        K.append(np.array([[float(calib_data_cam['fx']), float(calib_data_cam['skew']), float(calib_data_cam['cx'])],\n",
    "                   [0, float(calib_data_cam['fy']), float(calib_data_cam['cy'])],\n",
    "                   [0, 0, 1]])) # Intrinsics\n",
    "        rot_mat_cam = np.array([float(r) for r in calib_data_cam['r']]).reshape(3,3)\n",
    "        t_cam = np.array([float(t) for t in calib_data_cam['t']])\n",
    "\n",
    "        # Rotate cameras by Pi/2 around x in world frame\n",
    "        # camera frame to world frame\n",
    "        R_w, T_w = world_to_camera_persp(rot_mat_cam, t_cam)\n",
    "        # x_rotate -Pi/2 and z_rotate Pi\n",
    "        R_w_90, T_w_90 = rotate_cam(R_w, T_w, ang_x=-np.pi/2, ang_y=0, ang_z=np.pi)\n",
    "        # world frame to camera frame\n",
    "        R_c_90, T_c_90 = world_to_camera_persp(R_w_90, T_w_90)\n",
    "        # store in R and T\n",
    "        R.append(cv2.Rodrigues(R_c_90)[0].squeeze())\n",
    "        T.append(t_cam)\n",
    "\n",
    "toml_calib_file = Pose2Sim_scene_folder/'calibration'/f\"Calib_{'_'.join(cameras_to_use)}.toml\"\n",
    "toml_write(toml_calib_file, C, S, D, K, R, T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e6301",
   "metadata": {},
   "source": [
    "### Run Pose2Sim with model with hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc0fee",
   "metadata": {},
   "source": [
    "1. **Open the Config.toml model, search for the section `pose` -> `pose_model`, and set it to \"whole_body\".**\\\n",
    "Save and exit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df147f",
   "metadata": {},
   "source": [
    "2. **Run Pose2Sim.**\n",
    "\n",
    "N.B.: Calibration does not need to be run as we just converted the calibration files.\\\n",
    "N.B.: Synchronization does not need to be run either as the cameras were already synchronized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69539d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Pose2Sim_scene_folder)\n",
    "from Pose2Sim import Pose2Sim\n",
    "\n",
    "# Pose2Sim.calibration()\n",
    "Pose2Sim.poseEstimation()\n",
    "# Pose2Sim.synchronization()\n",
    "Pose2Sim.personAssociation()\n",
    "Pose2Sim.triangulation()\n",
    "Pose2Sim.filtering()\n",
    "Pose2Sim.markerAugmentation()\n",
    "Pose2Sim.kinematics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a93ad",
   "metadata": {},
   "source": [
    "3. **Check results in OpenSim GUI:**\n",
    "\n",
    "- File -> Open Model: Open the scaled `.osim` model from Demo_SinglePerson/kinematics\n",
    "- File -> Load Motion: Load the `.mot` motion from Demo_SinglePerson/kinematics\n",
    "- File -> Preview experimental data: Check the markers from Demo_SinglePerson/pose-3d\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c78785f",
   "metadata": {},
   "source": [
    "4. Optional:\n",
    "- You can also open the .trc and .mot file in Excel or any other spreadsheet software.\n",
    "- You can also look at the positions of cameras and the overlay of the skeleton and markers on videos by using the [Pose2Sim Blender add-on](https://github.com/davidpagnon/Pose2Sim_Blender). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d7afa",
   "metadata": {},
   "source": [
    "### Optional: Try it on a scene with multiple persons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3552b",
   "metadata": {},
   "source": [
    "Reproduce the previous steps on another scene (\"interactiv1_t2\", for example)\\\n",
    "Make sure you set `project` -> `multi_person` to \"true\" in COnfig.toml.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367da34",
   "metadata": {},
   "source": [
    "**Question:**\\\n",
    "***What do you notice? Why did it not work well?***\n",
    "\n",
    "**Answer:**\\\n",
    "We have plenty of cameras, but they are clustered in 2 almost identical locations. This makes it hard for the person association to work when they pass behind each other.\\\n",
    "Use the [Pose2Sim Blender add-on](https://github.com/davidpagnon/Pose2Sim_Blender) to visualize the problematic positions of cameras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c85f88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2089467",
   "metadata": {},
   "source": [
    "## Run on custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19601b5d",
   "metadata": {},
   "source": [
    "This time, we will run in the command line instead of from the notebook. As a reference, here is the documentation: [Pose2Sim documentation](https://github.com/perfanalytics/pose2sim).\n",
    "\n",
    "### Get your command line ready\n",
    "\n",
    "   It is easier to open PowerShell that Anaconda in a specific folder, so we are going to make sure conda is available in PowerShell.\\\n",
    "   Open `Anaconda Prompt` and type the following command:\n",
    "   ```bash\n",
    "   conda init powershell\n",
    "   ```\n",
    "   Now, you can go to any folder (e.g. `Day1_MotionTracking/Demo_customData`), right click on an empty space, and click `Open in Terminal`\\\n",
    "   `/!\\` Make sure you don't forget to type `conda activate Pose2Sim` everytime.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d197dc0",
   "metadata": {},
   "source": [
    "### Record and share videos from phones:\n",
    "\n",
    "4 people (hopefully) are going to volunteer for their phones to be used.\\\n",
    "Note that we could also use a GoPro, a webcam, or any camera, but sharing the files would be slightly more time consuming.\n",
    "\n",
    "1. **Set the cameras up:**\\\n",
    "   Set them in a such a way that they can see the full scene with as few occlusions as possible or undesired people in the background.\n",
    "2. **Record intrisic validation videos**:\\\n",
    "   Film the calibration checkerboard with each camera. Make sure that there is no switch of lens between when you are aiming at the center of the scene and when you are aiming at the checkerboard.\\\n",
    "   Also make sure that the checkerboard is oriented in as many directions as possible and covers a large part of the screen.\\\n",
    "3. **Record the scene:**\\\n",
    "   Measure something on the scene: squares on the floor, lines on the wall, ... It is also completely possible to temporarily put a table there, and then remove it.\\\n",
    "   Film it for about one second (the duration does not matter, we will extract a single frame).\\\n",
    "   /!\\ IMPORTANT! Now, make sure the cameras are not moved anymore!\n",
    "4. **Record a single person:**\\\n",
    "   It can be a person speaking in sign language, for example.\\ \n",
    "   Synchronization would work better if the person is doing a fast vertical motion at some point.\n",
    "5. **Record 2 people:**\\\n",
    "    Do any action you feel inspired to do.\\\n",
    "    Same instruction for synchronization.\n",
    "6. **Share the videos:**\\\n",
    "   Each phone owner can share all the videos on the Whatsapp group (preferably in HD).\\\n",
    "   This would be intrinsic calibration, extrinsic calibration, single person, multiple persons videos.\n",
    "7. Everyone from the group can then download the videos from Whatsapp \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff71ec8",
   "metadata": {},
   "source": [
    "### Organize the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate Pose2Sim\n",
    "! pip show Pose2Sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611af444",
   "metadata": {},
   "source": [
    "Copy-paste the \"Location\" the previous command gave you.\\\n",
    "Open it in your file explorer.\\\n",
    "Search for \"Pose2Sim\", and copy-paste `Demo_SinglePerson` and `Demo_MultiPerson` to Day1_MotionTracking.\n",
    "\n",
    "Now replace all the videos by the ones you just downloaded from Whatsapp and put them in the appropriate folders (`videos` and `calibration`).\\ \n",
    "Rename them accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cf0e7",
   "metadata": {},
   "source": [
    "### Edit the Configuration files\n",
    "\n",
    "Open both `Config.toml` files.\n",
    "\n",
    "Edit in particular: \n",
    "- `project` -> `multi_person` (or not) depending on the videos you are going to run.\n",
    "- `pose` -> `pose_model` to \"whole_body\" if you want finger motion.\n",
    "- `calibration` -> `calibration_type` to \"calculate\"\n",
    "- Change the `calibration` -> `calculate` -> `intrinsic` parameters according to the checkerboard you used.\n",
    "- Change the `calibration` -> `calculate` -> `extrinsic` -> `scene` according to the dimensions of the scene you measured and filmed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6685ea4",
   "metadata": {},
   "source": [
    "### Run Pose2Sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79611899",
   "metadata": {},
   "source": [
    "Right click in an empty space in the Single (and lated, multi) person folder, and click `Open in Terminal`.\n",
    "\n",
    "Type:\n",
    "```\n",
    "conda activate Pose2Sim\n",
    "ipython\n",
    "``` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caf75fb",
   "metadata": {},
   "source": [
    "Run, one line at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pose2Sim import Pose2Sim\n",
    "Pose2Sim.calibration()\n",
    "Pose2Sim.poseEstimation()\n",
    "Pose2Sim.synchronization()\n",
    "Pose2Sim.personAssociation()\n",
    "Pose2Sim.triangulation()\n",
    "Pose2Sim.filtering()\n",
    "Pose2Sim.markerAugmentation()\n",
    "Pose2Sim.kinematics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150d739e",
   "metadata": {},
   "source": [
    "Follow the pipeline step by step:\n",
    "- You'll see that calibration now tries to find the checkerboard corners, and then asks you to click (in the right order) on the points you measured in the scene.\n",
    "- There is now also a synchronization GUI that asks you which body point is moving the most, and at the person you want to synchronize on.\n",
    "- The other stages are unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73536d6",
   "metadata": {},
   "source": [
    "As before, you can visually check your results, either in OpenSim GUI, or in the [Pose2Sim Blender add-on](https://github.com/davidpagnon/Pose2Sim_Blender). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pose2Sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
