{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a5bea6b",
   "metadata": {},
   "source": [
    "# Pose2Sim workshop\n",
    "EnvisionBOX Summer School, 2025, Amsterdam. Presented by David Pagnon\n",
    "\n",
    "<bt><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d6ca9",
   "metadata": {},
   "source": [
    "`Pose2Sim` provides a workflow for 3D markerless kinematics (human or animal), as an alternative to traditional marker-based MoCap methods. \n",
    "\n",
    "**Pose2Sim** is free and open-source, requiring low-cost hardware but with research-grade accuracy and production-grade robustness. It gives maximum control over clearly explained parameters. Any combination of phones, webcams, or GoPros can be used with fully clothed subjects, so it is particularly adapted to the sports field, the doctor's office, or for outdoor 3D animation capture.\n",
    "\n",
    "***Note:*** For real-time analysis with a single camera, please consider **[Sports2D](https://github.com/davidpagnon/Sports2D)** (note that the motion must lie in the sagittal or frontal plane). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video, display\n",
    "\n",
    "display(Video('Pose2Sim_small.mp4', embed=True, width=1280, height=720))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd61b4e",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Install and import libraries](#install-and-import-libraries)\n",
    "2. [Install Pose2Sim](#install-pose2sim)\n",
    "    1. [Install miniconda](#install-miniconda)\n",
    "    2. [Create a new conda environment](#create-a-new-conda-environment)\n",
    "    3. [Install OpenSim](#install-opensim)\n",
    "    4. [Install Pose2Sim Core](#install-pose2sim-core)\n",
    "    5. [Optional: Install GPU libraries](#optional-install-gpu-libraries)\n",
    "3. [Try Pose2Sim Demo](#try-pose2sim-demo)\n",
    "    1. [Copy demo files](#copy-demo-files)\n",
    "    2. [Run Pose2Sim demo](#run-pose2sim-demo)\n",
    "4. [Run on the Tragic Talkers dataset](#run-on-the-tragic-talkers-dataset)\n",
    "    1. [Choose a subset](#choose-a-subset)\n",
    "    2. [Download videos and calibration files](#download-videos-and-calibration-files)\n",
    "    3. [Convert calibration files](#convert-calibration-files)\n",
    "    4. [Copy configuration file](#copy-configuration-file)\n",
    "    5. [Run pose estimation](#run-pose-estimation)\n",
    "    6. [Run person association and triangulation](#run-person-association-and-triangulation)\n",
    "    7. [Filter and run marker augmentation](#filter-and-run-marker-augmentation)\n",
    "    8. [Run scaling and inverse kinematics](#run-scaling-and-inverse-kinematics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f728f618",
   "metadata": {},
   "source": [
    "## Install and import libraries\n",
    "\n",
    "Install and import the libraries required for the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38efec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets ipyfilechooser opencv-python numpy\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "try: # For Google Colab\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "except ImportError: # For Jupyter Notebook\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fdac80",
   "metadata": {},
   "source": [
    "## Install Pose2Sim\n",
    "\n",
    "***N.B.*** *The following instructions are the same as those in the [Pose2Sim documentation](https://github.com/perfanalytics/pose2sim)*\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45040a10",
   "metadata": {},
   "source": [
    "1. Install [miniconda](https://docs.conda.io/en/latest/miniconda.html)\n",
    "2. Create a new conda environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda create -n Pose2Sim python=3.10 -y \n",
    "!conda activate Pose2Sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937335e",
   "metadata": {},
   "source": [
    "3. Install OpenSim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c opensim-org opensim -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce806b",
   "metadata": {},
   "source": [
    "Also install the [OpenSim GUI](https://simtk.org/projects/opensim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10e594c",
   "metadata": {},
   "source": [
    "4. Install Pose2Sim:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aca6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pose2sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a538154",
   "metadata": {},
   "source": [
    "5. *Optional:* Install the libraries for GPU support:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "!pip uninstall onnxruntime\n",
    "!pip install onnxruntime-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cd7311",
   "metadata": {},
   "source": [
    "## Try Pose2Sim Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e54082",
   "metadata": {},
   "source": [
    "Copy the Pose2Sim demo files to the current folder. Check how they are organized:\n",
    "\n",
    "```\n",
    "Trial\n",
    "├── calibration \\\n",
    "├── videos \\\n",
    "└── Config.toml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate Pose2Sim\n",
    "from Pose2Sim import Pose2Sim\n",
    "\n",
    "singleperson_demo_path = Path(Pose2Sim.__file__).parent.resolve() / 'Demo_SinglePerson'\n",
    "\n",
    "\n",
    "!cp -r {singleperson_demo_path} {Path.cwd()}/\n",
    "os.chdir(Path.cwd() / 'Demo_SinglePerson')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfac06a",
   "metadata": {},
   "source": [
    "**Run Pose2Sim demo:** This runs all stages of the pipeline on the Demo data with the default parameters. We will elaborate about :\n",
    "- **Calibration:** Determining the **intrinsic parameters** of the cameras (focal length, optical center, distortion, ...) and their **extrinsic parameters** (location and orientation).\\ \n",
    "  Here, we just convert a calibration file. Proper calibration will be done this afternoon when we collect our own data\n",
    "- **Pose estimation:** Detecting the points of interest in each video (joint centers, face, etc)\n",
    "- **Synchronization:** Make sure that the same time frame corresponds to the same body position.\\\n",
    "  I did not manage to make the tool work in Jupyter, so we are just going to skip it for now. We will do it again from the command line when we collect our own data.\n",
    "- **Person association:** Make sure that person 1 is associated with person 1 across all cameras\n",
    "- **Triangulation:** Transform all the 2D positions on videos to a 3D position in meters\n",
    "- **Filtering:** Results can be somewhat noisy, especially if we do not have many cameras, if they are not optimally placed, or if calibration is not perfect.\n",
    "- **Marker augmentation:** Add markers to the skeleton to facilitate the inverse kinematics stage.\n",
    "- **Kinematics:** Obtain a biomechanically consistent animated skeleton with adjusted and fixed limb lengths, and joint angle constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b62697",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pose2Sim.calibration()\n",
    "Pose2Sim.poseEstimation()\n",
    "# Pose2Sim.synchronization()\n",
    "Pose2Sim.personAssociation()\n",
    "Pose2Sim.triangulation()\n",
    "Pose2Sim.filtering()\n",
    "Pose2Sim.markerAugmentation()\n",
    "Pose2Sim.kinematics()\n",
    "\n",
    "# Or equivalently:\n",
    "#Pose2Sim.runAll() \n",
    "# Or:\n",
    "#Pose2Sim.runAll(do_calibration=True, do_poseEstimation=True, do_synchronization=True, do_personAssociation=True, do_triangulation=True, do_filtering=True, do_markerAugmentation=True, do_kinematics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be56bf2f",
   "metadata": {},
   "source": [
    "**Check results in OpenSim GUI:**\n",
    "\n",
    "- File -> Open Model: Open the scaled `.osim` model from Demo_SinglePerson/kinematics\n",
    "- File -> Load Motion: Load the `.mot` motion from Demo_SinglePerson/kinematics\n",
    "- File -> Preview experimental data: Check the markers from Demo_SinglePerson/pose-3d\n",
    "\n",
    "You can also open the .trc and .mot file in Excel or any other spreadsheet software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ab2e5",
   "metadata": {},
   "source": [
    "## Run on the Tragic Talkers dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e217b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Path.cwd().parent) # Go back to the original Day1_MotionTracking directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39310b0",
   "metadata": {},
   "source": [
    "### Choose a subset of the dataset to run on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_name = 'femalemonologue2_t3' # Among 'conversation1_t3', 'femalemonologue1_t2', 'femalemonologue2_t3', 'interactive1_t2', 'interactive4_t3', 'male_monologue2_t3'*\n",
    "cameras_to_use = ['01', '11', '12', '22'] # Among ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa884dd",
   "metadata": {},
   "source": [
    "### Convert the calibration files to the Pose2Sim format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290bb49c",
   "metadata": {},
   "source": [
    "Create the Pose2Sim folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addddc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pose2Sim import Pose2Sim\n",
    "\n",
    "sample_folder = Path.cwd().parent / 'Sample'\n",
    "scene_folder = sample_folder/scene_name\n",
    "calibration_folder = sample_folder/'camera_calibration_data'\n",
    "\n",
    "Pose2Sim_scene_folder = Path.cwd() / ('Demo_'+scene_name)\n",
    "Pose2Sim_scene_folder.mkdir(parents=True, exist_ok=True)\n",
    "(Pose2Sim_scene_folder / 'calibration').mkdir(parents=True, exist_ok=True)\n",
    "(Pose2Sim_scene_folder / 'videos').mkdir(parents=True, exist_ok=True)\n",
    "demo_config_path = Path(Pose2Sim.__file__).parent.resolve() / 'Demo_SinglePerson' / 'Config.toml'\n",
    "shutil.copyfile(demo_config_path, Pose2Sim_scene_folder / 'Config.toml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402825aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pose2Sim.calibration import toml_write\n",
    "from Pose2Sim.common import rotate_cam, world_to_camera_persp\n",
    "\n",
    "json_calib_files = sorted([list(calibration_folder.glob(f'*{nb}.json'))[0] for nb in cameras_to_use])\n",
    "ret, C, S, D, K, R, T = [], [], [], [], [], [], []\n",
    "for file_path in json_calib_files:\n",
    "    with open(file_path, 'r') as f:\n",
    "        calib_data_cam = json.load(f)['camera']\n",
    "        C.append(file_path.stem)  # Name\n",
    "        S.append([int(calib_data_cam['width']), int(calib_data_cam['height'])]) # Size\n",
    "        D.append([float(d) for d in calib_data_cam['distortion']][:4]) # Distortion\n",
    "        K.append(np.array([[float(calib_data_cam['fx']), float(calib_data_cam['skew']), float(calib_data_cam['cx'])],\n",
    "                   [0, float(calib_data_cam['fy']), float(calib_data_cam['cy'])],\n",
    "                   [0, 0, 1]])) # Intrinsics\n",
    "        rot_mat_cam = np.array([float(r) for r in calib_data_cam['r']]).reshape(3,3)\n",
    "        t_cam = np.array([float(t) for t in calib_data_cam['t']])\n",
    "\n",
    "        # Rotate cameras by Pi/2 around x in world frame\n",
    "        # camera frame to world frame\n",
    "        R_w, T_w = world_to_camera_persp(rot_mat_cam, t_cam)\n",
    "        # x_rotate -Pi/2 and z_rotate Pi\n",
    "        R_w_90, T_w_90 = rotate_cam(R_w, T_w, ang_x=-np.pi/2, ang_y=0, ang_z=np.pi)\n",
    "        # world frame to camera frame\n",
    "        R_c_90, T_c_90 = world_to_camera_persp(R_w_90, T_w_90)\n",
    "        # store in R and T\n",
    "        R.append(cv2.Rodrigues(R_c_90)[0].squeeze())\n",
    "        T.append(t_cam)\n",
    "\n",
    "toml_calib_file = Pose2Sim_scene_folder/'calibration'/f\"Calib_{'_'.join(cameras_to_use)}.toml\"\n",
    "toml_write(toml_calib_file, C, S, D, K, R, T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068e6301",
   "metadata": {},
   "source": [
    "### Run Pose2Sim with model with hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc0fee",
   "metadata": {},
   "source": [
    "**Open the Config.toml model, search for the section `pose` -> `pose_model`, and set it to \"whole_body\".**\\\n",
    "Save and exit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47df147f",
   "metadata": {},
   "source": [
    "**Run Pose2Sim.**\\\n",
    "N.B.: Calibration does not need to be run as we just converted the calibration files.\\\n",
    "N.B.: Synchronization does not need to be run either as the cameras were already synchronized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69539d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(Pose2Sim_scene_folder)\n",
    "from Pose2Sim import Pose2Sim\n",
    "\n",
    "# Pose2Sim.calibration()\n",
    "Pose2Sim.poseEstimation()\n",
    "# Pose2Sim.synchronization()\n",
    "Pose2Sim.personAssociation()\n",
    "Pose2Sim.triangulation()\n",
    "Pose2Sim.filtering()\n",
    "Pose2Sim.markerAugmentation()\n",
    "Pose2Sim.kinematics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a93ad",
   "metadata": {},
   "source": [
    "**Check results in OpenSim GUI:**\n",
    "\n",
    "- File -> Open Model: Open the scaled `.osim` model from Demo_SinglePerson/kinematics\n",
    "- File -> Load Motion: Load the `.mot` motion from Demo_SinglePerson/kinematics\n",
    "- File -> Preview experimental data: Check the markers from Demo_SinglePerson/pose-3d\n",
    "\n",
    "You can also open the .trc and .mot file in Excel or any other spreadsheet software."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d7afa",
   "metadata": {},
   "source": [
    "### Optional: Try it on a scene with multiple persons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be3552b",
   "metadata": {},
   "source": [
    "Reproduce the previous steps on another scene\\\n",
    "Make sure you set `project` -> `multi_person` to \"true\" in COnfig.toml.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367da34",
   "metadata": {},
   "source": [
    "***What do you notice? Why did it not work well?***\n",
    "\n",
    "<br>\n",
    "\n",
    "**Answer:**\\\n",
    "We have plenty of cameras, but they are clustered in 2 almost identical locations.\\\n",
    "Use the [Pose2Sim Blender add-on](https://github.com/davidpagnon/Pose2Sim_Blender) to visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2089467",
   "metadata": {},
   "source": [
    "## Run on custom data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19601b5d",
   "metadata": {},
   "source": [
    "This time, let's follow the documentaiton on the Pose2Sim GitHub page: \n",
    "\n",
    "[Pose2Sim documentation](https://github.com/perfanalytics/pose2sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d197dc0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pose2Sim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
